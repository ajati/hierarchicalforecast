{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeepAR in Wiki data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/Nixtla/hierarchicalforecast/blob/main/nbs/examples/AustralianDomesticTourism.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In many cases, only the time series at the lowest level of the hierarchies (bottom time series) are available. `HierarchicalForecast` has tools to create time series for all hierarchies. In this notebook we will see how to do it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# compute base forecast no coherent\n",
    "from statsforecast.core import StatsForecast\n",
    "from statsforecast.models import AutoARIMA, Naive\n",
    "import pandas as pd\n",
    "\n",
    "#obtain hierarchical reconciliation methods and evaluation\n",
    "from hierarchicalforecast.core import HierarchicalReconciliation\n",
    "from hierarchicalforecast.methods import BottomUp, TopDown, MiddleOut\n",
    "from datasetsforecast.hierarchical import HierarchicalData\n",
    "import numpy as np\n",
    "from statsforecast.models import ETS\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregate bottom time series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example we will use the [Tourism](https://otexts.com/fpp3/tourism.html) dataset from the [Forecasting: Principles and Practice](https://otexts.com/fpp3/) book. The dataset only contains the time series at the lowest level, so we need to create the time series for all hierarchies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load TourismSmall dataset\n",
    "Y_df, S, tags = HierarchicalData.load('./data', 'Wiki2')\n",
    "Y_df['ds'] = pd.to_datetime(Y_df['ds'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unq_ids = Y_df[\"unique_id\"].unique()\n",
    "len(unq_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(Y_df[Y_df[\"unique_id\"] == unq_ids[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tags.keys())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Train/Test sets\n",
    "\n",
    "We use the final horizon as test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HORIZON = 1\n",
    "FREQUENCY = \"1D\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test_df = Y_df.groupby('unique_id').tail(HORIZON)\n",
    "Y_train_df = Y_df.drop(Y_test_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_df = Y_train_df.set_index(\"unique_id\")\n",
    "Y_test_df = Y_test_df.set_index(\"unique_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_df.groupby('unique_id').size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing base forecasts\n",
    "\n",
    "The following cell computes the **base forecasts** for each time series in `Y_df` using the `auto_arima` and `naive` models. Observe that `Y_hat_df` contains the forecasts but they are not coherent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from statsforecast import StatsForecast\n",
    "from statsforecast.models import Theta\n",
    "\n",
    "fcst = StatsForecast(df=Y_train_df, \n",
    "                     models=[Theta(season_length=365)], \n",
    "                     freq=FREQUENCY, n_jobs=-1)\n",
    "Y_hat_df = fcst.forecast(h=HORIZON, fitted=True)\n",
    "Y_fitted_df = fcst.forecast_fitted_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reconcile forecasts\n",
    "\n",
    "The following cell makes the previous forecasts coherent using the `HierarchicalReconciliation` class. Since the hierarchy structure is not strict, we can't use methods such as `TopDown` or `MiddleOut`. In this example we use `BottomUp` and `MinTrace`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hierarchicalforecast.methods import BottomUp, MinTrace, ERM\n",
    "\n",
    "reconcilers = [\n",
    "    BottomUp(),\n",
    "    MinTrace(method='mint_shrink'),\n",
    "    MinTrace(method='ols'),\n",
    "    ERM(method='reg')\n",
    "]\n",
    "hrec = HierarchicalReconciliation(reconcilers=reconcilers)\n",
    "Y_rec_df = hrec.reconcile(Y_hat_df=Y_hat_df, Y_df=Y_fitted_df, S=S, tags=tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataframe `Y_rec_df` contains the reconciled forecasts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_rec_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation \n",
    "\n",
    "The `HierarchicalForecast` package includes the `HierarchicalEvaluation` class to evaluate the different hierarchies and also is capable of compute scaled metrics compared to a benchmark model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hierarchicalforecast.evaluation import HierarchicalEvaluation\n",
    "\n",
    "def rmse(y, y_hat):\n",
    "    return np.mean(np.sqrt(np.mean((y-y_hat)**2, axis=1)))\n",
    "\n",
    "def mase(y, y_hat, y_insample, seasonality=4):\n",
    "    errors = np.mean(np.abs(y - y_hat), axis=1)\n",
    "    scale = np.mean(np.abs(y_insample[:, seasonality:] - y_insample[:, :-seasonality]), axis=1)\n",
    "    return np.mean(errors / scale)\n",
    "\n",
    "def rmsse(y, y_hat, y_insample):\n",
    "    errors = np.mean(np.square(y - y_hat), axis=1)\n",
    "    scale = np.mean(np.square(y_insample[:, 1:] - y_insample[:, :-1]), axis=1)\n",
    "    return np.mean(np.sqrt(errors / scale))\n",
    "\n",
    "eval_tags = {}\n",
    "for k in tags.keys():\n",
    "    eval_tags[k] = tags[k]\n",
    "\n",
    "evaluator = HierarchicalEvaluation(evaluators=[rmse, mase, rmsse])\n",
    "evaluation = evaluator.evaluate(\n",
    "        Y_hat_df=Y_rec_df, Y_test_df=Y_test_df,\n",
    "        tags=eval_tags, Y_df=Y_train_df\n",
    ")\n",
    "evaluation = evaluation.drop('Overall')\n",
    "# evaluation.columns = ['Base', 'BottomUp', 'MinTrace(mint_shrink)', 'MinTrace(ols)']\n",
    "evaluation.columns = ['Base', 'BottomUp', 'MinTrace(ols)', 'MinTrace(mint_shrink)', 'ERM']\n",
    "evaluation = evaluation.applymap('{:.4f}'.format)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RMSE\n",
    "\n",
    "The following table shows the performance measured using RMSE across levels for each reconciliation method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_df = evaluation.query('metric == \"rmse\"')\n",
    "score_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MASE\n",
    "\n",
    "\n",
    "The following table shows the performance measured using MASE across levels for each reconciliation method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation.query('metric == \"mase\"')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RMSSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_df = evaluation.query('metric == \"rmsse\"')\n",
    "score_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_df.astype(float).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison fable\n",
    "\n",
    "Observe that we can recover the results reported by the [Forecasting: Principles and Practice](https://otexts.com/fpp3/tourism.html). The original results were calculated using the R package [fable](https://github.com/tidyverts/fable).\n",
    "\n",
    "![Fable's reconciliation results](./imgs/AustralianDomesticTourism-results-fable.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "- [Hyndman, R.J., & Athanasopoulos, G. (2021). \"Forecasting: principles and practice, 3rd edition: \n",
    "Chapter 11: Forecasting hierarchical and grouped series.\". OTexts: Melbourne, Australia. OTexts.com/fpp3 \n",
    "Accessed on July 2022.](https://otexts.com/fpp3/hierarchical.html)\n",
    "- [Rob Hyndman, Alan Lee, Earo Wang, Shanika Wickramasuriya, and Maintainer Earo Wang (2021). \"hts: Hierarchical and Grouped Time Series\". URL https://CRAN.R-project.org/package=hts. R package version 0.3.1.](https://cran.r-project.org/web/packages/hts/index.html)\n",
    "- [Mitchell O’Hara-Wild, Rob Hyndman, Earo Wang, Gabriel Caceres, Tim-Gunnar Hensel, and Timothy Hyndman (2021). \"fable: Forecasting Models for Tidy Time Series\". URL https://CRAN.R-project.org/package=fable. R package version 6.0.2.](https://CRAN.R-project.org/package=fable)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kdd23",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "325866f7fa4f95e720de7fe6e538be9ccc227e8ecad5205e286a691315428a88"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
